{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Using Different Base Learners in XGBoost\n",
    "\n",
    "XGBoost is a powerful gradient boosting framework that builds an ensemble of weak learners to create a strong predictive model.\n",
    "By default, XGBoost uses **decision trees** as its base learners, but it can also integrate **other types of learners**.\n",
    "\n",
    "### What is a Base Learner?\n",
    "A base learner (or weak learner) is the fundamental model used to make predictions in each boosting round.\n",
    "Each learner focuses on reducing the residual errors from the previous round.\n",
    "\n",
    "### Common Base Learners in XGBoost\n",
    "\n",
    "#### 1. **Decision Tree (Default)**\n",
    "- Works by creating a series of decision rules.\n",
    "- Each new tree corrects the errors of the previous trees.\n",
    "- Controlled by parameters like `max_depth`, `min_child_weight`, and `gamma`.\n",
    "\n",
    "#### 2. **Linear Models (Logistic/Linear Regression)**\n",
    "- Uses a linear function instead of a tree structure.\n",
    "- For regression tasks, it behaves like linear regression.\n",
    "- For classification, it can use logistic regression.\n",
    "- Set with `booster='gblinear'`.\n",
    "\n",
    "### How XGBoost Uses Base Learners\n",
    "- Each base learner is trained sequentially using **gradient boosting**.\n",
    "- It minimizes a loss function (e.g., log loss for classification, mean squared error for regression).\n",
    "- The final prediction is a combination (weighted sum) of all learners.\n",
    "\n",
    "### Key Parameters\n",
    "- **`booster`**\n",
    "  - Specifies the type of base learner.\n",
    "  - Options: `'gbtree'` (default), `'gblinear'`, `'dart'` (dropout trees).\n",
    "\n",
    "- **`learning_rate`**\n",
    "  - Controls the contribution of each learner.\n",
    "\n",
    "- **`n_estimators`**\n",
    "  - Number of boosting rounds (number of base learners to train).\n"
   ],
   "id": "3ae2ffb2f868cbf4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-09T20:36:52.289355Z",
     "start_time": "2025-09-09T20:36:39.188128Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T20:36:52.518112Z",
     "start_time": "2025-09-09T20:36:52.328899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"datasets\"\n",
    "file_name = \"ames_housing_trimmed_processed.csv\"\n",
    "housing = pd.read_csv(os.path.join(base_dir, file_name))\n",
    "\n",
    "housing.head()"
   ],
   "id": "cbd839a83d355474",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   Remodeled  GrLivArea  BsmtFullBath  BsmtHalfBath  ...  HouseStyle_1.5Unf  \\\n",
       "0          0       1710             1             0  ...                  0   \n",
       "1          0       1262             0             1  ...                  0   \n",
       "2          1       1786             1             0  ...                  0   \n",
       "3          1       1717             1             0  ...                  0   \n",
       "4          0       2198             1             0  ...                  0   \n",
       "\n",
       "   HouseStyle_1Story  HouseStyle_2.5Fin  HouseStyle_2.5Unf  HouseStyle_2Story  \\\n",
       "0                  0                  0                  0                  1   \n",
       "1                  1                  0                  0                  0   \n",
       "2                  0                  0                  0                  1   \n",
       "3                  0                  0                  0                  1   \n",
       "4                  0                  0                  0                  1   \n",
       "\n",
       "   HouseStyle_SFoyer  HouseStyle_SLvl  PavedDrive_P  PavedDrive_Y  SalePrice  \n",
       "0                  0                0             0             1     208500  \n",
       "1                  0                0             0             1     181500  \n",
       "2                  0                0             0             1     223500  \n",
       "3                  0                0             0             1     140000  \n",
       "4                  0                0             0             1     250000  \n",
       "\n",
       "[5 rows x 57 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Remodeled</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>...</th>\n",
       "      <th>HouseStyle_1.5Unf</th>\n",
       "      <th>HouseStyle_1Story</th>\n",
       "      <th>HouseStyle_2.5Fin</th>\n",
       "      <th>HouseStyle_2.5Unf</th>\n",
       "      <th>HouseStyle_2Story</th>\n",
       "      <th>HouseStyle_SFoyer</th>\n",
       "      <th>HouseStyle_SLvl</th>\n",
       "      <th>PavedDrive_P</th>\n",
       "      <th>PavedDrive_Y</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T20:36:52.623209Z",
     "start_time": "2025-09-09T20:36:52.602418Z"
    }
   },
   "cell_type": "code",
   "source": "X, y = housing.iloc[:,:-1], housing.iloc[:,-1]",
   "id": "9f022eb50dd89aef",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decision Trees As Base Learners",
   "id": "cfaa7c141f046b0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Train an XGBoost model to predict house prices using the provided dataset.\n",
    "The features (`X`) contain information about the houses and their locations, while the target (`y`) represents the house prices.\n",
    "\n",
    "By default, XGBoost uses decision trees as base learners, so no additional specification is needed for this.\n",
    "Instantiate the XGBoost regressor with the desired parameters.\n",
    "Fit the model on the training data to learn the relationship between the features and the target.\n",
    "Use the trained model to make predictions on the test data and evaluate its performance using an appropriate metric such as RMSE.\n"
   ],
   "id": "238c6aff6ae26d20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T20:37:09.809947Z",
     "start_time": "2025-09-09T20:36:52.645151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#1. Split df into training and testing sets, holding out 20% for testing. Use a random_state of 123.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 123)\n",
    "\n",
    "#2. Instantiate the XGBRegressor as xg_reg, using a seed of 123. Specify an objective of \"reg:squarederror\" and use 10 trees. Note: You don't have to specify booster=\"gbtree\" as this is the default.\n",
    "import xgboost as xgb\n",
    "xg_reg = xgb.XGBRegressor(objective = \"reg:squarederror\", n_estimators =10, seed = 123)\n",
    "\n",
    "#3. Fit xg_reg to the training data and predict the labels of the test set. Save the predictions in a variable called preds.\n",
    "xg_reg.fit(X_train, y_train)\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "#4. Compute the rmse using np.sqrt() and the mean_squared_error().\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (RMSE))\n",
    "\n",
    "\n"
   ],
   "id": "45926b2fbd5ea80c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 31292.976337\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Linear Base Learners\n",
    "\n",
    "Train an XGBoost model to predict house prices using a linear learner instead of trees.\n",
    "XGBoost supports linear base learners through the `gblinear` booster option, which creates a regularized linear regression model.\n",
    "\n",
    "To use this, define a parameter dictionary that specifies `\"booster\": \"gblinear\"`.\n",
    "Convert the training and testing datasets into `DMatrix` objects, which are optimized data structures required by XGBoost’s training API.\n",
    "Train the model using `xgb.train()` with the defined parameters and the training `DMatrix`.\n",
    "Use the trained model’s `.predict()` method on the test `DMatrix` to generate predictions.\n",
    "Evaluate the predictions using an appropriate metric such as RMSE to measure model performance.\n"
   ],
   "id": "fb2b77d24b0aa6dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T20:57:43.854958Z",
     "start_time": "2025-09-09T20:57:43.770658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#1. Create two DMatrix objects - DM_train for the training set (X_train and y_train), and DM_test (X_test and y_test) for the test set.\n",
    "DM_train = xgb.DMatrix(data=X_train, label = y_train)\n",
    "DM_test = xgb.DMatrix(data=X_test, label = y_test)\n",
    "\n",
    "\n",
    "#2. Create a parameter dictionary that defines the \"booster\" type you will use (\"gblinear\") as well as the \"objective\" you will minimize (\"reg:squarederror\").\n",
    "params = {'objective':'reg:squarederror',\n",
    "          'booster':\"gblinear\"}\n",
    "\n",
    "#3. Train the model using xgb.train(). You have to specify arguments for the following parameters: params, dtrain, and num_boost_round.\n",
    "xg = xgb.train(params=params, dtrain=DM_train, num_boost_round = 5)\n",
    "\n",
    "#4. Predict the labels on the test set using xg_reg.predict(), passing it DM_test. Assign to preds.\n",
    "xg_preds = xg.predict(DM_test)\n",
    "\n",
    "# Compute and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test,preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ],
   "id": "8c06ccc08159cb06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 31292.976337\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluating XGBoost Model Quality with Cross-Validation.\n",
    "\n",
    "Use cross-validation to measure model quality on the Ames housing dataset.\n",
    "The evaluation will focus on two metrics: **Root Mean Squared Error (RMSE)** and **Mean Absolute Error (MAE)**.\n",
    "\n",
    "Steps:\n",
    "\n",
    "* Define parameters for the XGBoost model, starting with `\"objective\": \"reg:squarederror\"` and specifying the evaluation metric (`\"rmse\"` or `\"mae\"`).\n",
    "* Convert the features and target into a `DMatrix` for optimized computation.\n",
    "* Perform 4-fold cross-validation with 5 boosting rounds using `xgb.cv()`.\n",
    "* For RMSE: extract the RMSE values from the output and print the result from the final boosting round.\n",
    "* Repeat the process for MAE by updating the metric in the parameters to `\"mae\"` and printing the final boosting round MAE.\n",
    "\n",
    "This allows you to compare how different evaluation metrics represent model performance on the same dataset.\n"
   ],
   "id": "5a485edacc687fff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:16:44.515559Z",
     "start_time": "2025-09-09T21:16:44.441002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#1. Perform 4-fold cross-validation with 5 boosting rounds and \"rmse\" as the metric.\n",
    "\n",
    "#RMSE\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params1 = {'objective':'reg:squarederror', 'max_depth':4}\n",
    "\n",
    "#Performing cross validation.\n",
    "cv_results1 = xgb.cv(dtrain=housing_dmatrix, params=params1, nfold=4, num_boost_round = 5, metrics='rmse', as_pandas=True, seed=123)\n",
    "\n",
    "print(cv_results1)\n",
    "print((cv_results1['test-rmse-mean']).tail(1))\n",
    "\n"
   ],
   "id": "a8f22c384a7775a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
      "0     61729.274347      679.377718    63760.373921    2933.496745\n",
      "1     49654.722560      757.696043    53641.473273    3504.687699\n",
      "2     41325.179705      702.570217    46796.539109    3500.230673\n",
      "3     35351.338939      772.520024    41986.507917    4018.899377\n",
      "4     31020.037762      574.099506    39337.103754    4583.588151\n",
      "4    39337.103754\n",
      "Name: test-rmse-mean, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:17:04.393933Z",
     "start_time": "2025-09-09T21:17:04.315911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#1. Perform 4-fold cross-validation with 5 boosting rounds and \"rmse\" as the metric.\n",
    "\n",
    "#MAE\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params1 = {'objective':'reg:squarederror', 'max_depth':4}\n",
    "\n",
    "#Performing cross validation.\n",
    "cv_results1 = xgb.cv(dtrain=housing_dmatrix, params=params1, nfold=4, num_boost_round = 5, metrics='mae', as_pandas=True, seed=123)\n",
    "\n",
    "print(cv_results1)\n",
    "print((cv_results1['test-mae-mean']).tail(1))\n",
    "\n"
   ],
   "id": "1e66cb2365334151",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
      "0    43978.370783     265.516103   44551.030843    875.854839\n",
      "1    34677.517623     229.638967   35869.958037   1015.100363\n",
      "2    28338.053913     290.958119   30144.292723    902.020896\n",
      "3    24076.657948     451.048602   26492.798309    835.506913\n",
      "4    21115.815254     428.025143   24289.425664    994.137976\n",
      "4    24289.425664\n",
      "Name: test-mae-mean, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ccc31ef1bf7c0cf3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
